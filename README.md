#  Used-Car-Price-Prediction-Seller-Decision-Intelligence-System

An **end-to-end, industry-grade machine learning system** that predicts used car prices and converts raw ML outputs into **business-ready pricing decisions** using confidence scoring, explainability, and human-in-the-loop routing.

This project is inspired by real-world automotive marketplaces (e.g., C2B used-car platforms) and is designed to reflect **production ML engineering practices**, not just model training.

---

## ğŸ“Œ Key Highlights

* End-to-end ML pipeline: **data â†’ model â†’ decisions â†’ API**
* Business-aware **feature engineering** (depreciation, usage, market demand)
* Robust **model evaluation beyond RMSE** (MAPE, bucket-wise errors)
* **Explainable AI (SHAP)** for global & per-car justification
* **Decision Intelligence Layer** (auto-quote vs manual review)
* Fully deployed as a **FastAPI service**
* Production concerns handled: schema alignment, validation, confidence routing

---

## ğŸ§  Problem Statement

Used car pricing is inherently noisy due to:

* Non-linear depreciation
* Varying usage patterns
* Brand & market perception
* Sparse data for premium / rare models

A pure ML prediction is **not sufficient**. A real system must:

1. Predict a fair price
2. Know **when to trust itself**
3. Explain *why* a price was assigned
4. Route risky cases to human reviewers

This project solves all four.

---

## ğŸ—ï¸ System Architecture

**High-level flow:**

```
Raw Data
   â†“
Data Cleaning & Validation
   â†“
EDA & Business Insights
   â†“
Feature Engineering
   â†“
Model Training (XGBoost)
   â†“
Evaluation & Error Analysis
   â†“
Explainability (SHAP)
   â†“
Decision Intelligence Layer
   â†“
FastAPI Deployment
```

ğŸ“Œ *Add architecture diagram image here*

---

## ğŸ“‚ Project Structure

```
Used-Car-Price-Prediction-Seller-Decision-Intelligence-System/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ cleaned_used_cars.csv
â”‚       â””â”€â”€ featured_used_cars.csv
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_cleaning.ipynb
â”‚   â”œâ”€â”€ 02_eda.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ feature_engineering.py
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â”œâ”€â”€ save_feature_scheme.py
â”‚   â”œâ”€â”€ data_cleaning.py
â”‚   â”œâ”€â”€ explainability.py
â”‚   â”œâ”€â”€ decision_engine.py
â”‚   â””â”€â”€ run_decision_engine.py
â”‚
â”œâ”€â”€ app/
â”‚   â””â”€â”€ main.py          # FastAPI app
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ xgboost_price_model.pkl
â”‚   â””â”€â”€ feature_schema.json
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ğŸ” Phase-wise Breakdown

### Phase 1 â€” Data Cleaning & Validation

* Removed missing / invalid entries
* Normalized numeric fields (engine, power, mileage)
* Standardized categorical values
* Ensured no target leakage

Output:

* `cleaned_used_cars.csv`

---

### Phase 2 â€” Exploratory Data Analysis (EDA)

EDA was driven by **business questions**, not visuals.

Key insights:

* Sharp depreciation in first 5â€“7 years
* Usage intensity (km/year) matters more than raw km
* Automatic transmission & popular brands command premiums
* Premium cars show higher pricing variance

ğŸ“Œ *Add EDA plots here: price vs age, km vs price, brand boxplots*

---

### Phase 3 â€” Feature Engineering

Engineered features to encode real-world pricing logic:

**Usage & Depreciation**

* `vehicle_age`
* `km_per_year`

**Performance Signals**

* `max_power`
* `power_per_cc`

**Market Demand Signals**

* `brand_popularity` (frequency-based)
* `model_rarity`

**Categorical Encoding**

* One-hot encoding for fuel, transmission, seller type
* Stable schema saved for inference

Output:

* `featured_used_cars.csv`

---

### Phase 4 â€” Modeling

Models trained & compared:

| Model             | Purpose                |
| ----------------- | ---------------------- |
| Linear Regression | Baseline sanity check  |
| Random Forest     | Non-linear baseline    |
| **XGBoost**       | Final production model |

Primary metric:

* **MAPE** (business-aligned for pricing systems)

Final choice:

* **XGBoost** due to lowest MAPE and stable behavior

---

### Phase 5 â€” Evaluation & Error Analysis

Beyond global metrics:

* Bucket-wise MAPE (low / mid / high / premium)
* Relative error distribution
* High-risk prediction identification

Sample results:

| Price Segment | MAPE |
| ------------- | ---- |
| Low           | ~18% |
| Mid           | ~13% |
| High          | ~10% |
| Premium       | ~11% |

ğŸ“Œ *Add error distribution & bucket MAPE plots here*

---

### Phase 6 â€” Explainability (SHAP)

Used **SHAP (TreeExplainer)** to ensure transparency.

**Global explainability:**

* Top drivers: vehicle age, power, mileage, brand popularity

**Local explainability:**

* Per-car force plots explaining price push & pull

This enables:

* Seller-facing justification
* Internal audit & trust

ğŸ“Œ *Add SHAP summary plot & force plot images here*

---

### Phase 7 â€” Seller Decision Intelligence Layer

Converted ML predictions into **business decisions**.

For each car:

* Predicted price
* Confidence score
* Price band
* Auto-quote vs manual review
* Reviewer notes

Decision rules:

| Confidence | Action                 |
| ---------- | ---------------------- |
| â‰¥ 0.85     | Auto-Quote             |
| 0.70â€“0.85  | Auto-Quote (Wide Band) |
| < 0.70     | Manual Review          |

This mirrors real marketplace workflows.

---

### Phase 8 â€” FastAPI Deployment

Exposed the full system via API:

```
POST /predict_price
```

Features:

* Strict input schema
* Feature schema alignment
* Domain validation (reject invalid cars)
* Explainable response

Sample response:

```json
{
  "predicted_price": 450000,
  "confidence_score": 0.9,
  "decision": "AUTO_QUOTE",
  "price_band": [427500, 472500],
  "key_price_drivers": ["vehicle_age", "km_driven", "max_power"],
  "reviewer_notes": ["Manual transmission"]
}
```

---

## ğŸ§ª Testing

* Swagger UI (`/docs`) used for manual testing
* Tested normal, edge, and invalid inputs
* Domain validation prevents non-physical cars

---

## ğŸ§  Key Engineering Learnings

* Feature engineering > model choice
* Schema alignment is critical in production ML
* Tree models fallback to learned baselines
* ML systems must handle invalid input explicitly
* Explainability is mandatory for pricing systems

---

## ğŸ“ˆ Results Summary

* Stable MAPE across segments
* ~85â€“90% predictions auto-quotable
* ~10â€“15% routed to manual review
* Explainable, auditable decisions

ğŸ“Œ *Add final results summary plots here*

---

## ğŸš€ How to Run

```bash
pip install -r requirements.txt
uvicorn app.main:app --reload
```

Open:

```
http://127.0.0.1:8000/docs
```

---

## ğŸ“Œ Future Improvements

* Confidence calibration using residual modeling
* Time-aware pricing trends
* Seller-side UX integration
* Online learning / retraining pipeline

---

## ğŸ Conclusion

This project demonstrates how to build a **real-world ML pricing system**, not just a predictive model. It integrates data science, ML engineering, explainability, and business decision logic - closely mirroring production systems used in large-scale marketplaces.

---

**Author**: Zeno Nongmaithem 
>**Focus**: Data Science, Machine Learning, Decision Systems

